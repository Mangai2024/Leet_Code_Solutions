Mini-batch Gradient Descent project
`src/minibatch_gd.py` â€” runnable example (ready-to-use)
Save this as `src/minibatch_gd.py`.

```python
import numpy as np

def minibatch_gd_epoch(X, y, w, b, batch_size=64, lr=1e-3, seed=None):
    n = X.shape[0]
    rng = np.random.default_rng(seed)
    idx = rng.permutation(n)
    for start in range(0, n, batch_size):
        batch_idx = idx[start:start+batch_size]
        Xb = X[batch_idx]
        yb = y[batch_idx]
        y_pred = Xb @ w + b
        m = Xb.shape[0]
        err = y_pred - yb
        grad_w = (2.0/m) * (Xb.T @ err)
        grad_b = (2.0/m) * err.sum()
        w = w - lr * grad_w
        b = b - lr * grad_b
    return w, b

if __name__ == "__main__":
    X = np.array([[1.0],[2.0],[3.0],[4.0]])
    y = np.array([2.0,4.0,6.0,8.0])
    w = np.zeros(1); b = 0.0
    w, b = minibatch_gd_epoch(X, y, w, b, batch_size=2, lr=0.1, seed=1)
    print("After one epoch: w =", w, "b =", b)
6) requirements.txt (example)
nginx
Copy code
numpy
matplotlib   # optional for plots in notebook
jupyterlab   # optional if you use notebooks
7) Add tests (optional but good)
Create tests/test_minibatch.py with a simple assertion:

Add tests (optional but good)
import numpy as np
from src.minibatch_gd import minibatch_gd_epoch

def test_minibatch():
    X = np.array([[1.0],[2.0],[3.0],[4.0]])
    y = np.array([2.0,4.0,6.0,8.0])
    w = np.zeros(1); b = 0.0
    w2, b2 = minibatch_gd_epoch(X,y,w,b,batch_size=2,lr=0.1,seed=1)
    assert isinstance(w2, np.ndarray)
    assert w2.shape == (1,)
